# Hand-Gesture-Controlled AI Camera Filters

## Project Description

This project is a real-time AI-powered camera filter application that allows users to switch between various image processing filters using hand gestures. Built with OpenCV, MediaPipe, and SpeechRecognition, it enables gesture-based and voice-controlled filter selection, making it an innovative and interactive experience.

## Key Features

- **Hand Gesture Recognition**: Uses MediaPipe to detect hand gestures and change filters dynamically.
- **Multiple Filters**: Includes Blur, Canny Edge Detection, Sepia, Grayscale, Sketch, Emboss, and Sharpen effects.
- **Voice Control (Optional)**: Users can switch filters using voice commands instead of gestures.
- **Real-Time Processing**: Uses OpenCV to apply filters in real time with a webcam.
- **Google Colab Compatible**: Modified to work with Google Colab (for image processing) and local systems (for real-time webcam use).

## Tech Stack

- **Programming Language**: Python
- **Libraries**: OpenCV, NumPy, MediaPipe, SpeechRecognition
- **Platforms**: Google Colab / Jupyter Notebook / Local PC
- **Key Technologies**: Computer Vision & AI for gesture-based interaction

## Usage

1. **Google Colab**:  
   - Upload an image to the script.
   - Use hand gestures to switch between filters dynamically.
   - Optionally, use voice commands to change filters.

2. **Local PC**:
   - Run the script with a webcam connected.
   - Use hand gestures to switch between filters in real time.
   - Optionally, use voice commands for filter switching.

## Perfect For

AI & OpenCV enthusiasts who want to explore real-time computer vision applications!
